1. find
-name 按名字查找
-perm 根据权限查找
-ctime Cn +m 根据创建时间查找，-n n天内，+n n天之前
-mtime Cn +n 最后修改时间
-exec command {} \; 对每条记录执行command
-ok command {}\;同上
例：find . Cname “*.log” Cexec ls Cal {} \;
find /var -name "*.log" -mtime +10 -exec ls -l {} \;
find . -name "*复件*.txt" -ok rm {} \ ;

2. grep
grep Cc “qwe” *.txt 只返回匹配的行数
grep Cn 输出行号
grep “2010-5-1[0-9]” myfile 10号到19号的
grep “^[^123]” myfile 不是以1，2，3大头的
grep “4\{2\}” myfile 连续2个4
grep “4\{2,\}” myfile 连续至少2个4
grep “4\{2,5\}” myfile 连续2到5个4
grep “^$” myfile 空行
grep “\^” myfile 查找^符号，用\过滤掉转义

3. wc
Wc用来计算文件字符数，字节数，行数等信息的
Wc Cl <myfile 返回myfile的行数

4. awk（很好很强大）
awk ‘{print $0}’ myfile 显示myfile的所有域($0)，分隔符为空格(默认)
awk CF “asdf” ‘{print $1}’ myfile 显示1域，分隔符asdf
awk -F ": " 'BEGIN {print "hire_date\n-------------------"}{print $1}' messages |head 
//awk中的BEGIN {command} END{command} 结构，指定头和尾的操作，不同于一般的BEGIN END块结构

Awk中特殊元字符：＋ , ?   //+匹配所有，?匹配单个字符
匹配操作符：~ , !~         //~匹配，!~不匹配

head messages |awk '$0 ~ /21:59/' 匹配21:59的行，相当于grep功能了,不过awk可以更精确的控制具体域！
head messages |awk '$0 !~ /21:59/' 不匹配21:59的行(grep -i)

[mysql@node1 ~]$ head messages |awk '{if($3=="21:59:48") print $0}' 
May 10 21:59:48 node1 dhclient: DHCPREQUEST on eth1 to 192.168.217.254 port 67
May 10 21:59:48 node1 dhclient: DHCPACK from 192.168.217.254
May 10 21:59:48 node1 dhclient: bound to 192.168.217.133 -- renewal in 843 seconds.
//AWK自己的控制流结构，相比一般shell语法似乎更接近于C

5. sed
sed 是一种在线编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有改变。

-n 是打印不匹配的行，默认是打印所有
-e 后面跟脚本，直到新行或者遇到-e结束。如果不给-e，则第一个命令直到新行才结束
-f 后面跟脚本文件

基本编辑命令：
p 打印匹配行
= 显示行号
a\ 在定位行后添加信息(新行)
i\ 在定位行前插入信息(新行)
d 删除定位行
c\ 替换定位的行内容，注意是整行内容
s/re/string 用string替换正则表达式re。
g表示行内全面替换。

注意，pattern的内容都是正则表达式
sed ‘2p’ myfile 打印所有行
sed Cn ‘2p’ myfile 答应第二行，-n是打印不匹配的行，默认是打印所有
sed Cn ‘1,7p’ myfile 打印1到7行(1,$就是1到最后一行)
sed Cn ‘/fuyar/p’ myfile 打印匹配fuyar的行，模式匹配方式
sed Cn ‘2,/fuyar/p’ myfile 从第二行开始到匹配到fuyar结束。行号方式跟模式匹配方式的结合使用
=号：Print the current line number.
sed Cn ‘/^$/=’ myfile 显示空行行号
sed Cn Ce ‘/^$/=’ Ce ‘/^$/p’ myfile 显示空行行号并打印
sed -n 's/param/& hellow /p' yy.sh 在param后加上hellow
sed -n 's/param/ hellow &/p' yy.sh 在param前加hellow

6. sort
-c 检查文件是否已排序
-u unique的意思，排序后重复记录只显示一条
-r reverse,反序
-n 数字排序
-kn 按第n个域进行排序，相当于+ n-1 Cn，现在推荐用-k

sort -t: -k3 messages | head 等同于sort -t: +2 -3 messages | head

7. uniq
从一个文本中去除或禁止重复行，这里的重复行指的是相邻的！可与sort结合使用。
-c 显示每条记录重复的行数
-u 只显示不重复的行，即-c为1的那些行
-d只显示记录重复的行，但每条只显示1次

8. split
分割文件，分割后的文件为：prefix[aa-zz]，例如yyaa，yyab….yyzz
一般格式：split [options] infile outfile_prefix
[options]:
-b n 以大小为n(k,m)分割
-l n 每个文件的分割的行数n
-n 同-l n

几个命令结合使用可以编写一些简单的shell脚本。
例：监测磁盘使用情况，每分钟检测一次，如果快满了(使用超过90%)则给root发封邮件提醒。
[root@node1 ~]# cat space_oversee.sh 
#!/bin/bash
#space_oversee.sh by fuyar(417226209).
#to oversee the space usage of all disks.
#oversee per minute.

while [ 1 -lt 2 ]
do
for DISK in `df | awk '{print $1}' | sed -n '2,/$/p'`
        do
                USED=`df | grep "$DISK" |awk '{print $5}'|sed -n 's/%//p'`
                if [ $USED -ge 90 ]
                        then echo "`date`:$DISK is nearly full: ${USED}%."|mail root
                fi
        done
sleep 60
done

该脚本可放后台执行

1.find / -type f -user logread -ls >/dev/null
查找用户logread所有的普通文件并输出至屏幕；
2.find . -name "*.java" -mtime -2
查找当前目录下最近2天修改的java文件；
3.grep -in exp file
在file文件中搜索exp字符串，不区分大小写并显示行号(-c,只显示行数；-l,只显示文件名)；
4.grep -e "^0" file(grep -e "g$" file)
在file文件中搜索以0开头的行，或者以g结束的行。grep命令支持ERE，如grep -E '(x1|x2)x3' file，搜索匹配x1x3或x2x3模式的行；
5.sed -n '/exp1/, /exp2/p' file
在file文件中搜索与exp1,exp2模式匹配的之间的行数据；
6.sed -n '/exp1/w file1
> /exp2/w file2
> ' file
在file文件中搜索与exp1匹配的行，写入到file1文件中，搜索与exp2匹配的行，写入到file2文件中。也可以指定行，如sed -n '1,7w file1
> 8,$w file2' file，将file文件的1-7行写入到file1中，8-末尾行写入到file2中；
7.sed '4i\ 
string1\
> string2
> ' file
在file文件中第4行前插入string1和string2两行；
8.sed 'a\
exp1\
exp2
' file
在file文件中每行后追加两行exp1和exp2；
9.sed '/^[ ]*$/d' file
在file文件中删除空行，[]中包含a space and a tab；
10.sed 's/exp1/exp2/g' file
将file文件中所有匹配exp1模式的字符串替换为匹配exp2模式的字符串。sed 's/^/exp1/' file，sed 's/$/exp1/' file，将file文件每行开头或者结束的地方插入exp1。sed还支持记忆模式，支持IRE；
11.awk -F"|" ' { print $NF}' file
输出file每行最后一个字段的内容
awk用于格式化报文或者从文件中抽取数据包．
　　1.$awk '{print $0}' gefforey.txt | tee gefforey.doc
该命令将在屏幕输出gefforey.txt文件内容并将其内容复制到gefforey.doc文件中．
　　2.$awk -F: '{print $1}' gefforey.log
该命令以:为单位读取gefforey.log文件中第一列内容．
　　３.$awk 'BEGIN {print "Name   Belt\n------------"} {print $1"\t"$3}' gefforey.txt
该命令将在屏幕首先输出"Name   Belt"，第二行输出"------------"，并在输出文件内容的时候，每列之间间隔一个TAB位．可以在print语句之后加上END {print "end of output"}，那么将会在文件内容输出结束的时候打印"end of output"．
       4.$awk '$2 ~ /^baidu$/ {print $0}' gefforey.txt
该命令显示gefforey.txt文件中以空格分隔的第二列字符串是"baidu"的所有行．
　　5.$awk '{if($2 ~ /^baidu$/) print $0}' gefforey.txt
该命令判断如果某行第二列字符串为"baidu",则打印出该行．
       6.$awk '{if($2 < $3) print $0}' gefforey.txt
该命令显示判断如果某行第二列值小于第三列值，则打印该行．awk的条件操作符有：
< 小于，> = 大于等于，< = 小于等于，~ 匹配正则表达式，= = 等于，!~ 不匹配正则表达式，!= 不等于
　　7.$awk '{if($2 =="google1" && $3=="google2") print $0}' gefforey.txt
该命令判断如果某行第二列值为"google1"并且第三列值为"google2"，则打印出该行．awk的逻辑表达式有：&& AND，|| O R，! 非．
　　8.$awk '{print NF,NR,$0} END{print FILENAME}' gefforey.txt
该命令会输出浏览记录的域个数和已读的记录数，并在输出结尾打印文件名．awk内置的变量有：
A R G C 命令行参数个数
A R G V 命令行参数排列
E N V I R O N 支持队列中系统环境变量的使用
FILENAME a w k浏览的文件名
F N R 浏览文件的记录数
F S 设置输入域分隔符，等价于命令行- F选项
N F 浏览记录的域个数
N R 已读的记录数
O F S 输出域分隔符
O R S 输出记录分隔符
R S 控制记录分隔符
（附：1.N F的一个强大功能是将变量$ P W D的返回值传入a w k并显示其目录。这里需要指定域分隔
符/．命令为：echo $PWD | awk -F/ '{print $NF}';
           2.显示文件名，命令为：echo "/usr/local/etc/rc.sybase" | awk -F/ '{print $NF}'．
　　9.$awk '{name=$1; belt=$3;if(belt ~ /yellow/) print name "is belt" belt }' gefforey.txt
该命令将第一列的值赋给变量name,第三行的值赋给变量belt，并打印语句．awk允许在语句中进行赋值操作，赋值操作符有：=， +=， *=， / =， %=， ^ = ．
　　10.$awk 'gsub(/111/,222) {print $0}' gefforey.txt
该命令将文件中所有包含111的数字替换为222，awk的内置函数有：
g s u b ( r, s ) 在整个$ 0中用s替代r
g s u b ( r, s , t ) 在整个t中用s替代r
i n d e x ( s , t ) 返回s中字符串t的第一位置
l e n g t h ( s ) 返回s长度
m a t c h ( s , r ) 测试s是否包含匹配r的字符串
s p l i t ( s , a , f s ) 在f s上将s分成序列a
s p r i n t ( f m t , e x p ) 返回经f m t格式化后的e x p
s u b ( r, s ) 用$ 0中最左边最长的子串代替s
s u b s t r ( s , p ) 返回字符串s中从p开始的后缀部分
s u b s t r ( s , p , n ) 返回字符串s中从p开始长度为n的后缀部分
g s u b函数有点类似于s e d查找和替换。它允许替换一个字符串或字符为另一个字符串或字
符，并以正则表达式的形式执行。第一个函数作用于记录$ 0，第二个g s u b函数允许指定目标，
然而，如果未指定目标，缺省为$ 0。
i n d e x（s，t）函数返回目标字符串s中查询字符串t的首位置。l e n g t h函数返回字符串s字符
长度。m a t c h函数测试字符串s是否包含一个正则表达式r定义的匹配。s p l i t使用域分隔符f s将
字符串s划分为指定序列a。s p r i n t函数类似于p r i n t f函数（以后涉及），返回基本输出格式f m t的
结果字符串e x p。s u b（r，s）函数将用s替代$ 0中最左边最长的子串，该子串被（ r）匹配。
s u b（s，p）返回字符串s在位置p后的后缀。s u b s t r（s，p，n）同上，并指定子串长度为n。
　　11.$echo "65" | awk '{printf "//%c\n",$0}'
该命令管道输出65到awk，并观察其ASCII字符．awk的printf函数格式如下：
% c A S C I I字符
% d 整数
% e 浮点数，科学记数法
% f 浮点数，例如（1 2 3 . 4 4）
% g a w k决定使用哪种浮点数转换e或者f
% o 八进制数
% s 字符串
% x 十六进制数

awk命令也许是linux系统中最为复杂的命令，需要好好的练习！
